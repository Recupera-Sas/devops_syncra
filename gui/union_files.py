import os
from web.pyspark_session import get_spark_session
from pyspark.sql import DataFrame
from datetime import datetime
from web.save_files import save_to_csv
 
spark = get_spark_session()

def read_file_with_delimiter(file_path: str) -> DataFrame:
    """ğŸ“– Read file and detect delimiter automatically"""
    print(f"   ğŸ” Detecting delimiter for: {os.path.basename(file_path)}")
    with open(file_path, 'r') as f:
        first_line = f.readline()
        if ',' in first_line:
            delimiter = ','
            print(f"   âœ… Detected delimiter: COMMA (,)")
        elif ';' in first_line:
            delimiter = ';'
            print(f"   âœ… Detected delimiter: SEMICOLON (;)")
        elif '\t' in first_line:
            delimiter = '\t'
            print(f"   âœ… Detected delimiter: TAB (\\t)")
        else:
            raise ValueError(f"âŒ No delimiter detected in file: {os.path.basename(file_path)}")
    
    print(f"   ğŸ“Š Reading CSV file...")
    df = spark.read.csv(file_path, sep=delimiter, header=True, inferSchema=True)
    print(f"   âœ… File loaded - Shape: ({df.count()} rows, {len(df.columns)} columns)")
    return df, delimiter

def merge_files(input_directory: str, output_directory: str):
    """ğŸ”„ Merge multiple CSV/TXT files into a single file"""
    
    print("=" * 70)
    print("ğŸš€ STARTING FILE MERGE PROCESS")
    print("=" * 70)
    print(f"ğŸ“ Input directory: {input_directory}")
    print(f"ğŸ“ Output directory: {output_directory}")
    print("-" * 70)
    
    # ğŸ“‚ Get all CSV and TXT files
    file_paths = [os.path.join(input_directory, f) for f in os.listdir(input_directory) 
                  if f.endswith('.csv') or f.endswith('.txt')]
    
    print(f"ğŸ” Found {len(file_paths)} file(s) to process:")
    for i, file_path in enumerate(file_paths, 1):
        print(f"   {i}. {os.path.basename(file_path)}")
    
    if not file_paths:
        print("âŒ No CSV or TXT files found in the input directory!")
        return
    
    print("-" * 70)
    print("ğŸ“– Reading files...")
    
    merged_df = None
    found_delimiter = None
    total_files_processed = 0
    total_rows = 0

    for i, file_path in enumerate(file_paths, 1):
        print(f"\nğŸ“Š Processing file {i}/{len(file_paths)}: {os.path.basename(file_path)}")
        
        try:
            df, delimiter = read_file_with_delimiter(file_path)
            found_delimiter = delimiter
            file_rows = df.count()
            total_rows += file_rows
            
            if merged_df is None:
                merged_df = df
                print(f"   ğŸ”„ Created initial DataFrame")
            else:
                merged_df = merged_df.unionByName(df, allowMissingColumns=True)
                print(f"   ğŸ”„ Merged with existing DataFrame")
            
            total_files_processed += 1
            print(f"   âœ… SUCCESS - Added {file_rows:,} rows")
            
        except Exception as e:
            print(f"   âŒ ERROR reading file: {e}")
            continue

    print("-" * 70)
    
    if merged_df is not None:
        print(f"ğŸ“Š MERGE COMPLETED:")
        print(f"   â€¢ Files processed: {total_files_processed}/{len(file_paths)}")
        print(f"   â€¢ Total rows before deduplication: {total_rows:,}")
        print(f"   â€¢ Current DataFrame shape: ({merged_df.count():,} rows, {len(merged_df.columns)} columns)")
        
        # ğŸ§¹ Remove duplicates
        print(f"\nğŸ§¹ Removing duplicates...")
        initial_count = merged_df.count()
        merged_df = merged_df.dropDuplicates()
        final_count = merged_df.count()
        duplicates_removed = initial_count - final_count
        
        print(f"   â€¢ Rows before: {initial_count:,}")
        print(f"   â€¢ Rows after: {final_count:,}")
        print(f"   â€¢ Duplicates removed: {duplicates_removed:,}")
        
        # ğŸ”§ Determine process type based on column names
        columns = merged_df.columns
        print(f"\nğŸ” Analyzing columns: {columns}")
        
        if "2_" in columns and "3_" in columns:
            Type_Process = "Conversion"
            print(f"   ğŸ·ï¸ Process type: CONVERSION (special columns detected)")
        else:
            Type_Process = "Union_Archivos"
            print(f"   ğŸ·ï¸ Process type: FILE MERGE")
        
        # ğŸ’¾ Set saving parameters
        Partitions = 1
        delimiter = ";"
        
        print(f"\nğŸ’¾ Saving parameters:")
        print(f"   â€¢ Process type: {Type_Process}")
        print(f"   â€¢ Partitions: {Partitions}")
        print(f"   â€¢ Delimiter: '{delimiter}'")
        print(f"   â€¢ Output directory: {output_directory}")
        
        # ğŸ’½ Save the merged file
        print(f"\nğŸ“¤ Saving merged file...")
        save_to_csv(merged_df, output_directory, Type_Process, Partitions, delimiter)
        
        print(f"\nâœ… FINAL STATISTICS:")
        print(f"   â€¢ Total files merged: {total_files_processed}")
        print(f"   â€¢ Final unique rows: {final_count:,}")
        print(f"   â€¢ Total columns: {len(merged_df.columns)}")
        print(f"   â€¢ Process completed successfully!")
        
    else:
        print("âŒ No files could be processed successfully!")
        print("ğŸ’¡ Please check that files contain valid data and delimiters.")
    
    print("=" * 70)
    print("ğŸ FILE MERGE PROCESS COMPLETED")
    print("=" * 70)